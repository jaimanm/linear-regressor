{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: datahub.io has good datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy, math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(sqft)    float64\n",
      "bedrooms      float64\n",
      "floors        float64\n",
      "age           float64\n",
      "price         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('data/houses.csv')\n",
    "\n",
    "# for cars.csv:\n",
    "# target = df['price']\n",
    "# predictors = df.drop('price', axis = 1)\n",
    "# numeric_predictors = feature_values.select_dtypes(exclude=['object'])\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['age', 'bedrooms', 'floors', 'size(sqft)']], df[['price']], train_size=0.7, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale/normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_norm = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_norm = pd.DataFrame(\n",
    "    scaler.fit_transform(X_test), columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays for vectorized calculations\n",
    "# X_norm = X_norm.to_numpy()\n",
    "# X_test_norm = X_test_norm.to_numpy()\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (70, 4)\n",
      "X_test.shape: (30, 4)\n",
      "y_train.shape: (70, 1)\n",
      "y_test.shape: (30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (4,), b_init type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# initial parameters\n",
    "m, n = X_train.shape\n",
    "# w_init = np.zeros(n)\n",
    "# b_init = 0\n",
    "\n",
    "b_init = 785.1811367994083\n",
    "w_init = np.array([0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "  '''\n",
    "  Predict values using weights and inputs\n",
    "  \n",
    "  Args:\n",
    "  X (ndarray (m,n)) : examples with multiple features\n",
    "  w (ndarray (n,))  : model parameters\n",
    "  b (scalar)        : model parameter\n",
    "\n",
    "  Returns:\n",
    "  p (scalar)        : prediction \n",
    "  '''\n",
    "\n",
    "  p = np.dot(X, w) + b\n",
    "\n",
    "  return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([459.99999762, 231.99999837, 177.99999899])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_train, w_init, b_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b):\n",
    "  '''\n",
    "  Computes cost for a model using current parameters\n",
    "  \n",
    "  Args:\n",
    "  X (ndarray (m,n)) : data, m examples with n features\n",
    "  y (ndarray (m,))  : target values\n",
    "  w (ndarray (n,))  : model parameters\n",
    "  b (scalar)        : model parameter\n",
    "  \n",
    "  Returns:\n",
    "  cost (scalar)     : cost\n",
    "  '''\n",
    "\n",
    "  m,_ = X.shape\n",
    "  pred = predict(X, w, b)\n",
    "  cost = ((pred - y)**2).sum()\n",
    "  cost = cost / (2 * m)\n",
    "\n",
    "  return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5578904045996674e-12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cost(X_train, y_train, w_init, b_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b):\n",
    "  '''\n",
    "  Computes the gradient(slope of cost function)\n",
    "\n",
    "  Args:\n",
    "  X (ndarray (m,n))    : data, m examples with n features\n",
    "  y (ndarray (m,))     : target values\n",
    "  w (ndarray (n,))     : model parameters\n",
    "  b (scalar)           : model parameter\n",
    "\n",
    "  Returns:\n",
    "  dj_dw (ndarray (n,)) : gradient of the cost w.r.t. the parameters w\n",
    "  dj_db (scalar)       : gradient of the cost w.r.t. the parameter b\n",
    "  '''\n",
    "\n",
    "  m, n = X.shape\n",
    "\n",
    "  err = predict(X, w, b) - y\n",
    "  dj_dw = np.dot(err, X) / m\n",
    "  dj_db = err.sum() / m\n",
    "\n",
    "  return dj_dw, dj_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: -1.6739251122999121e-06\n",
      "dj_dw at initial w,b: \n",
      " [-2.72623574e-03 -6.27197255e-06 -2.21745574e-06 -6.92403377e-05]\n"
     ]
    }
   ],
   "source": [
    "# compute and display gradient\n",
    "tmp_dj_dw, tmp_dj_db = compute_gradient(X_train, y_train, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, alpha, num_iters):\n",
    "  '''\n",
    "  Performs batch gradient descent to learn the optimal parameters w and b.\n",
    "  Updates parameters by taking num_iters gradient steps with learning rate alpha\n",
    "\n",
    "  Args:\n",
    "  X (ndarray (n,m))   : data, m examples with n features\n",
    "  y (ndarray (m,))    : target values\n",
    "  w_in (ndarray (n,)) : initial model parameters\n",
    "  b_in (scalar)       : initial model parameter\n",
    "  alpha (float)       : learning rate\n",
    "  num_iters (int)     : number of iterations to run gradient descent\n",
    "\n",
    "  Returns:\n",
    "  w (ndarray (n,))    : updated values of parameters\n",
    "  b (scalar)          : updated value of parameter\n",
    "  '''\n",
    "\n",
    "  # store the cost j over each iteration\n",
    "  J_history = []\n",
    "\n",
    "  # avoid changing original w inside function\n",
    "  w_copy = copy.deepcopy(w_in)\n",
    "  b = b_in\n",
    "\n",
    "  for i in range(num_iters):\n",
    "\n",
    "    # calculate gradient\n",
    "    dj_dw, dj_db = compute_gradient(X, y, w, b)\n",
    "\n",
    "    # update parameters using the gradient at each iteration\n",
    "    w -= alpha * dj_dw\n",
    "    b -= alpha * dj_db\n",
    "\n",
    "    # record cost at each iteration\n",
    "    if i < 100000:  # to prevent resource exhaustion\n",
    "      J_history.append(compute_cost(X, y, w, b))\n",
    "\n",
    "    # display cost 10 times during gradient descent\n",
    "    if i % math.ceil(num_iters/10) == 0:\n",
    "      print(f'Iteration: {i}:   Cost: {J_history[-1]:8.2f}')\n",
    "\n",
    "  return w, b, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'w, b found by gradient descent: {w_final}, {b_final:0.2f}')\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    print(\n",
    "        f'prediction: {predict(X_test_norm, w_final, b_final)[i]:0.2f}, target value: {y_test[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Dec 19 2022, 20:24:16) [GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
